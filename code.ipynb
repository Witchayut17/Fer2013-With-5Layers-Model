{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5612540c-9477-49dd-b718-a4c8932484e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 5060\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e67a1f7-340a-4a4d-91c5-0c9cf03a225c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.1940, Accuracy: 0.0936\n",
      "Validation Loss: 2.1209, Validation Accuracy: 0.0420\n",
      "Epoch [2/100], Loss: 2.1396, Accuracy: 0.0909\n",
      "Validation Loss: 2.0337, Validation Accuracy: 0.1145\n",
      "Epoch [3/100], Loss: 2.0504, Accuracy: 0.1879\n",
      "Validation Loss: 1.9518, Validation Accuracy: 0.3176\n",
      "Epoch [4/100], Loss: 1.9657, Accuracy: 0.2944\n",
      "Validation Loss: 1.8739, Validation Accuracy: 0.4189\n",
      "Epoch [5/100], Loss: 1.9085, Accuracy: 0.3517\n",
      "Validation Loss: 1.8237, Validation Accuracy: 0.4219\n",
      "Epoch [6/100], Loss: 1.8708, Accuracy: 0.3752\n",
      "Validation Loss: 1.8047, Validation Accuracy: 0.4423\n",
      "Epoch [7/100], Loss: 1.8439, Accuracy: 0.4026\n",
      "Validation Loss: 1.7560, Validation Accuracy: 0.4664\n",
      "Epoch [8/100], Loss: 1.8267, Accuracy: 0.4212\n",
      "Validation Loss: 1.7445, Validation Accuracy: 0.5103\n",
      "Epoch [9/100], Loss: 1.8029, Accuracy: 0.4365\n",
      "Validation Loss: 1.7126, Validation Accuracy: 0.5150\n",
      "Epoch [10/100], Loss: 1.7904, Accuracy: 0.4462\n",
      "Validation Loss: 1.6881, Validation Accuracy: 0.4899\n",
      "Epoch [11/100], Loss: 1.7721, Accuracy: 0.4584\n",
      "Validation Loss: 1.6871, Validation Accuracy: 0.5282\n",
      "Epoch [12/100], Loss: 1.7575, Accuracy: 0.4678\n",
      "Validation Loss: 1.6970, Validation Accuracy: 0.5373\n",
      "Epoch [13/100], Loss: 1.7507, Accuracy: 0.4745\n",
      "Validation Loss: 1.6342, Validation Accuracy: 0.5340\n",
      "Epoch [14/100], Loss: 1.7441, Accuracy: 0.4777\n",
      "Validation Loss: 1.6447, Validation Accuracy: 0.5340\n",
      "Epoch [15/100], Loss: 1.7252, Accuracy: 0.4860\n",
      "Validation Loss: 1.6355, Validation Accuracy: 0.5503\n",
      "Epoch [16/100], Loss: 1.7212, Accuracy: 0.4933\n",
      "Validation Loss: 1.6487, Validation Accuracy: 0.5626\n",
      "Epoch [17/100], Loss: 1.7109, Accuracy: 0.4968\n",
      "Validation Loss: 1.6068, Validation Accuracy: 0.5579\n",
      "Epoch [18/100], Loss: 1.7024, Accuracy: 0.5022\n",
      "Validation Loss: 1.6200, Validation Accuracy: 0.5723\n",
      "Epoch [19/100], Loss: 1.7003, Accuracy: 0.5045\n",
      "Validation Loss: 1.6070, Validation Accuracy: 0.5709\n",
      "Epoch [20/100], Loss: 1.6845, Accuracy: 0.5119\n",
      "Validation Loss: 1.5889, Validation Accuracy: 0.5528\n",
      "Epoch [21/100], Loss: 1.6789, Accuracy: 0.5169\n",
      "Validation Loss: 1.5998, Validation Accuracy: 0.5714\n",
      "Epoch [22/100], Loss: 1.6677, Accuracy: 0.5225\n",
      "Validation Loss: 1.5727, Validation Accuracy: 0.5895\n",
      "Epoch [23/100], Loss: 1.6690, Accuracy: 0.5248\n",
      "Validation Loss: 1.5738, Validation Accuracy: 0.5914\n",
      "Epoch [24/100], Loss: 1.6586, Accuracy: 0.5282\n",
      "Validation Loss: 1.5651, Validation Accuracy: 0.5895\n",
      "Epoch [25/100], Loss: 1.6501, Accuracy: 0.5334\n",
      "Validation Loss: 1.5844, Validation Accuracy: 0.5554\n",
      "Epoch [26/100], Loss: 1.6486, Accuracy: 0.5335\n",
      "Validation Loss: 1.5664, Validation Accuracy: 0.6118\n",
      "Epoch [27/100], Loss: 1.6376, Accuracy: 0.5420\n",
      "Validation Loss: 1.5447, Validation Accuracy: 0.6013\n",
      "Epoch [28/100], Loss: 1.6245, Accuracy: 0.5488\n",
      "Validation Loss: 1.5413, Validation Accuracy: 0.6055\n",
      "Epoch [29/100], Loss: 1.6314, Accuracy: 0.5452\n",
      "Validation Loss: 1.5419, Validation Accuracy: 0.6125\n",
      "Epoch [30/100], Loss: 1.6143, Accuracy: 0.5572\n",
      "Validation Loss: 1.5395, Validation Accuracy: 0.6239\n",
      "Epoch [31/100], Loss: 1.6181, Accuracy: 0.5534\n",
      "Validation Loss: 1.5279, Validation Accuracy: 0.6065\n",
      "Epoch [32/100], Loss: 1.6099, Accuracy: 0.5595\n",
      "Validation Loss: 1.5512, Validation Accuracy: 0.6167\n",
      "Epoch [33/100], Loss: 1.6067, Accuracy: 0.5633\n",
      "Validation Loss: 1.5331, Validation Accuracy: 0.6313\n",
      "Epoch [34/100], Loss: 1.5947, Accuracy: 0.5637\n",
      "Validation Loss: 1.5091, Validation Accuracy: 0.6160\n",
      "Epoch [35/100], Loss: 1.5929, Accuracy: 0.5694\n",
      "Validation Loss: 1.5307, Validation Accuracy: 0.6241\n",
      "Epoch [36/100], Loss: 1.5864, Accuracy: 0.5704\n",
      "Validation Loss: 1.5117, Validation Accuracy: 0.6246\n",
      "Epoch [37/100], Loss: 1.5853, Accuracy: 0.5704\n",
      "Validation Loss: 1.5020, Validation Accuracy: 0.6215\n",
      "Epoch [38/100], Loss: 1.5771, Accuracy: 0.5761\n",
      "Validation Loss: 1.5112, Validation Accuracy: 0.6083\n",
      "Epoch [39/100], Loss: 1.5695, Accuracy: 0.5782\n",
      "Validation Loss: 1.4901, Validation Accuracy: 0.6359\n",
      "Epoch [40/100], Loss: 1.5631, Accuracy: 0.5817\n",
      "Validation Loss: 1.5016, Validation Accuracy: 0.6315\n",
      "Epoch [41/100], Loss: 1.5600, Accuracy: 0.5836\n",
      "Validation Loss: 1.4832, Validation Accuracy: 0.6417\n",
      "Epoch [42/100], Loss: 1.5629, Accuracy: 0.5854\n",
      "Validation Loss: 1.4957, Validation Accuracy: 0.6364\n",
      "Epoch [43/100], Loss: 1.5522, Accuracy: 0.5907\n",
      "Validation Loss: 1.4853, Validation Accuracy: 0.6376\n",
      "Epoch [44/100], Loss: 1.5522, Accuracy: 0.5927\n",
      "Validation Loss: 1.5080, Validation Accuracy: 0.6332\n",
      "Epoch [45/100], Loss: 1.5510, Accuracy: 0.5908\n",
      "Validation Loss: 1.4888, Validation Accuracy: 0.6362\n",
      "Epoch [46/100], Loss: 1.5299, Accuracy: 0.6024\n",
      "Validation Loss: 1.4771, Validation Accuracy: 0.6441\n",
      "Epoch [47/100], Loss: 1.5116, Accuracy: 0.6126\n",
      "Validation Loss: 1.4612, Validation Accuracy: 0.6547\n",
      "Epoch [48/100], Loss: 1.5095, Accuracy: 0.6122\n",
      "Validation Loss: 1.4738, Validation Accuracy: 0.6520\n",
      "Epoch [49/100], Loss: 1.5118, Accuracy: 0.6117\n",
      "Validation Loss: 1.4654, Validation Accuracy: 0.6501\n",
      "Epoch [50/100], Loss: 1.5010, Accuracy: 0.6184\n",
      "Validation Loss: 1.4639, Validation Accuracy: 0.6643\n",
      "Epoch [51/100], Loss: 1.5014, Accuracy: 0.6194\n",
      "Validation Loss: 1.4708, Validation Accuracy: 0.6624\n",
      "Epoch [52/100], Loss: 1.4866, Accuracy: 0.6257\n",
      "Validation Loss: 1.4556, Validation Accuracy: 0.6626\n",
      "Epoch [53/100], Loss: 1.4808, Accuracy: 0.6279\n",
      "Validation Loss: 1.4603, Validation Accuracy: 0.6594\n",
      "Epoch [54/100], Loss: 1.4758, Accuracy: 0.6271\n",
      "Validation Loss: 1.4524, Validation Accuracy: 0.6633\n",
      "Epoch [55/100], Loss: 1.4727, Accuracy: 0.6349\n",
      "Validation Loss: 1.4544, Validation Accuracy: 0.6575\n",
      "Epoch [56/100], Loss: 1.4772, Accuracy: 0.6310\n",
      "Validation Loss: 1.4476, Validation Accuracy: 0.6629\n",
      "Epoch [57/100], Loss: 1.4674, Accuracy: 0.6342\n",
      "Validation Loss: 1.4520, Validation Accuracy: 0.6636\n",
      "Epoch [58/100], Loss: 1.4687, Accuracy: 0.6351\n",
      "Validation Loss: 1.4462, Validation Accuracy: 0.6650\n",
      "Epoch [59/100], Loss: 1.4629, Accuracy: 0.6365\n",
      "Validation Loss: 1.4460, Validation Accuracy: 0.6654\n",
      "Epoch [60/100], Loss: 1.4601, Accuracy: 0.6412\n",
      "Validation Loss: 1.4445, Validation Accuracy: 0.6731\n",
      "Epoch [61/100], Loss: 1.4590, Accuracy: 0.6412\n",
      "Validation Loss: 1.4420, Validation Accuracy: 0.6640\n",
      "Epoch [62/100], Loss: 1.4548, Accuracy: 0.6402\n",
      "Validation Loss: 1.4403, Validation Accuracy: 0.6640\n",
      "Epoch [63/100], Loss: 1.4452, Accuracy: 0.6420\n",
      "Validation Loss: 1.4491, Validation Accuracy: 0.6636\n",
      "Epoch [64/100], Loss: 1.4495, Accuracy: 0.6460\n",
      "Validation Loss: 1.4466, Validation Accuracy: 0.6617\n",
      "Epoch [65/100], Loss: 1.4399, Accuracy: 0.6488\n",
      "Validation Loss: 1.4454, Validation Accuracy: 0.6671\n",
      "Epoch [66/100], Loss: 1.4418, Accuracy: 0.6499\n",
      "Validation Loss: 1.4338, Validation Accuracy: 0.6698\n",
      "Epoch [67/100], Loss: 1.4432, Accuracy: 0.6499\n",
      "Validation Loss: 1.4399, Validation Accuracy: 0.6657\n",
      "Epoch [68/100], Loss: 1.4352, Accuracy: 0.6463\n",
      "Validation Loss: 1.4363, Validation Accuracy: 0.6743\n",
      "Epoch [69/100], Loss: 1.4330, Accuracy: 0.6508\n",
      "Validation Loss: 1.4311, Validation Accuracy: 0.6747\n",
      "Epoch [70/100], Loss: 1.4397, Accuracy: 0.6522\n",
      "Validation Loss: 1.4313, Validation Accuracy: 0.6687\n",
      "Epoch [71/100], Loss: 1.4319, Accuracy: 0.6492\n",
      "Validation Loss: 1.4400, Validation Accuracy: 0.6680\n",
      "Epoch [72/100], Loss: 1.4386, Accuracy: 0.6511\n",
      "Validation Loss: 1.4424, Validation Accuracy: 0.6712\n",
      "Epoch [73/100], Loss: 1.4235, Accuracy: 0.6538\n",
      "Validation Loss: 1.4363, Validation Accuracy: 0.6678\n",
      "Epoch [74/100], Loss: 1.4202, Accuracy: 0.6585\n",
      "Validation Loss: 1.4338, Validation Accuracy: 0.6668\n",
      "Epoch [75/100], Loss: 1.4227, Accuracy: 0.6595\n",
      "Validation Loss: 1.4270, Validation Accuracy: 0.6724\n",
      "Epoch [76/100], Loss: 1.4121, Accuracy: 0.6629\n",
      "Validation Loss: 1.4307, Validation Accuracy: 0.6719\n",
      "Epoch [77/100], Loss: 1.4006, Accuracy: 0.6641\n",
      "Validation Loss: 1.4349, Validation Accuracy: 0.6784\n",
      "Epoch [78/100], Loss: 1.4026, Accuracy: 0.6652\n",
      "Validation Loss: 1.4329, Validation Accuracy: 0.6761\n",
      "Epoch [79/100], Loss: 1.4034, Accuracy: 0.6698\n",
      "Validation Loss: 1.4268, Validation Accuracy: 0.6743\n",
      "Epoch [80/100], Loss: 1.4015, Accuracy: 0.6701\n",
      "Validation Loss: 1.4234, Validation Accuracy: 0.6759\n",
      "Epoch [81/100], Loss: 1.4046, Accuracy: 0.6692\n",
      "Validation Loss: 1.4308, Validation Accuracy: 0.6796\n",
      "Epoch [82/100], Loss: 1.4069, Accuracy: 0.6636\n",
      "Validation Loss: 1.4278, Validation Accuracy: 0.6780\n",
      "Epoch [83/100], Loss: 1.3960, Accuracy: 0.6689\n",
      "Validation Loss: 1.4250, Validation Accuracy: 0.6773\n",
      "Epoch [84/100], Loss: 1.4000, Accuracy: 0.6706\n",
      "Validation Loss: 1.4276, Validation Accuracy: 0.6768\n",
      "Epoch [85/100], Loss: 1.3880, Accuracy: 0.6740\n",
      "Validation Loss: 1.4230, Validation Accuracy: 0.6808\n",
      "Epoch [86/100], Loss: 1.3905, Accuracy: 0.6714\n",
      "Validation Loss: 1.4242, Validation Accuracy: 0.6782\n",
      "Epoch [87/100], Loss: 1.3921, Accuracy: 0.6729\n",
      "Validation Loss: 1.4215, Validation Accuracy: 0.6789\n",
      "Epoch [88/100], Loss: 1.3854, Accuracy: 0.6758\n",
      "Validation Loss: 1.4221, Validation Accuracy: 0.6763\n",
      "Epoch [89/100], Loss: 1.3942, Accuracy: 0.6770\n",
      "Validation Loss: 1.4247, Validation Accuracy: 0.6791\n",
      "Epoch [90/100], Loss: 1.3859, Accuracy: 0.6806\n",
      "Validation Loss: 1.4236, Validation Accuracy: 0.6803\n",
      "Epoch [91/100], Loss: 1.3832, Accuracy: 0.6747\n",
      "Validation Loss: 1.4232, Validation Accuracy: 0.6819\n",
      "Epoch [92/100], Loss: 1.3803, Accuracy: 0.6776\n",
      "Validation Loss: 1.4266, Validation Accuracy: 0.6821\n",
      "Epoch [93/100], Loss: 1.3851, Accuracy: 0.6801\n",
      "Validation Loss: 1.4233, Validation Accuracy: 0.6791\n",
      "Epoch [94/100], Loss: 1.3775, Accuracy: 0.6828\n",
      "Validation Loss: 1.4243, Validation Accuracy: 0.6805\n",
      "Epoch [95/100], Loss: 1.3824, Accuracy: 0.6816\n",
      "Validation Loss: 1.4277, Validation Accuracy: 0.6814\n",
      "Epoch [96/100], Loss: 1.3778, Accuracy: 0.6810\n",
      "Validation Loss: 1.4245, Validation Accuracy: 0.6791\n",
      "Epoch [97/100], Loss: 1.3763, Accuracy: 0.6783\n",
      "Validation Loss: 1.4248, Validation Accuracy: 0.6808\n",
      "Early stopping triggered\n",
      "Test Accuracy: 0.6728\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "class FER2013Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "def load_images_from_folder(base_dir, image_size=(48, 48)):\n",
    "    images, labels = [], []\n",
    "\n",
    "    for label in os.listdir(base_dir):\n",
    "        folder = os.path.join(base_dir, label)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "\n",
    "        for img_name in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, image_size)\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    images = np.array(images, dtype=\"float32\") / 255.0\n",
    "    images = images.reshape(-1, 48, 48, 1)\n",
    "\n",
    "    return images, np.array(labels)\n",
    "\n",
    "train_dir = r\"C:\\Users\\usEr\\.cache\\kagglehub\\datasets\\msambare\\fer2013\\versions\\1\\train\"\n",
    "test_dir  = r\"C:\\Users\\usEr\\.cache\\kagglehub\\datasets\\msambare\\fer2013\\versions\\1\\test\"\n",
    "\n",
    "X_train, y_train = load_images_from_folder(train_dir)\n",
    "X_test, y_test   = load_images_from_folder(test_dir)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = label_encoder.fit_transform(y_train)\n",
    "y_test_enc  = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_cat = np.eye(7)[y_train_enc]  \n",
    "y_test_cat  = np.eye(7)[y_test_enc]\n",
    "\n",
    "X_train, X_val, y_train_cat, y_val_cat, y_train_enc, y_val_enc = train_test_split(\n",
    "    X_train,\n",
    "    y_train_cat,\n",
    "    y_train_enc,\n",
    "    test_size=0.15,\n",
    "    stratify=y_train_enc,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(512)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(1024)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout4 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(1024)\n",
    "        self.dropout5 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512)\n",
    "        self.dropout_fc1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(256)\n",
    "        self.dropout_fc2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = torch.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool4(x)\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x = torch.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.dropout5(x)\n",
    "        \n",
    "        x = self.global_avg_pool(x)      \n",
    "        x = torch.flatten(x, 1)             \n",
    "        \n",
    "        x = torch.relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.dropout_fc1(x)\n",
    "        \n",
    "        x = torch.relu(self.bn_fc2(self.fc2(x)))\n",
    "        x = self.dropout_fc2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=10),\n",
    "    v2.RandomAffine(\n",
    "    degrees=10,\n",
    "    translate=(0.1, 0.1),\n",
    "    scale=(0.9, 1.1)\n",
    "),\n",
    "    v2.RandomErasing(p=0.3, scale=(0.02, 0.25)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "val_test_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "train_dataset = FER2013Dataset(X_train, y_train_enc, transform=train_transform)\n",
    "val_dataset = FER2013Dataset(X_val, y_val_enc, transform=val_test_transform)\n",
    "test_dataset = FER2013Dataset(X_test, y_test_enc, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNNModel(num_classes=7).to(device)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_enc), y=y_train_enc)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).cuda()\n",
    "\n",
    "model = CNNModel().cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1, weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0008, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.6,\n",
    "    patience=3,\n",
    "    min_lr=1e-5\n",
    ")\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {test_correct/test_total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66000d-8c4b-4567-aaeb-2eec2f3b0198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "Accuracy           : 0.6718\n",
      "Precision : 0.6738\n",
      "Recall    : 0.6718\n",
      "F1-Score  : 0.6685\n",
      "Inference time     : 1.69 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_weighted_only(model, test_loader, device):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            \n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_w = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_w    = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1_w        = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    print(\"Classification Report\")\n",
    "    \n",
    "    print(f\"Accuracy           : {accuracy:.4f}\")\n",
    "    print(f\"Precision : {precision_w:.4f}\")\n",
    "    print(f\"Recall    : {recall_w:.4f}\")\n",
    "    print(f\"F1-Score  : {f1_w:.4f}\")\n",
    "    print(f\"Inference time     : {inference_time:.2f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision_w,\n",
    "        'recall': recall_w,\n",
    "        'f1': f1_w,\n",
    "        'inference_time': inference_time\n",
    "    }\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "results = evaluate_weighted_only(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
